{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "sys.path.append(os.path.join(\"..\"))\n",
    "\n",
    "#Utility function - Neural networks with numpy\n",
    "from utils.neuralnetwork import NeuralNetwork\n",
    "\n",
    "# Machine learning tools\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import datasets #data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an argument parser from argparse\n",
    "ap = argparse.ArgumentParser(description = \"[INFO] Classify MNIST data and print out performance report\")\n",
    "    \n",
    "#size of training data in percentage\n",
    "ap.add_argument(\"-trs\", \"--train_size\",\n",
    "                    required = False,\n",
    "                    default = 0.8,\n",
    "                    type = float,\n",
    "                    help = \"The size of the training data as a percentage. DEFAULT = 0.8 (80%)\")\n",
    "    \n",
    "#size of training data in percentage \n",
    "ap.add_argument(\"-tes\", \"--test_size\",\n",
    "                    required = False,\n",
    "                    default = 0.2,\n",
    "                    type = float,\n",
    "                    help = \"The size of the test data as a percentage. DEFAULT = 0.2 (20%)\")\n",
    "\n",
    "#Create an argument parser from argparse\n",
    "args = vars(ap.parse_args())\n",
    "    \n",
    "#Save in variables for readability\n",
    "trs = args[\"train_size\"] #training size\n",
    "tes = args[\"test_size\"] #test size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch data\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - X.min())/(X.max() - X.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create training data and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    train_size=7500,\n",
    "                                                    test_size=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels from integers to vectors\n",
    "y_train = LabelBinarizer().fit_transform(y_train)\n",
    "y_test = LabelBinarizer().fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "[INFO] NeuralNetwork: 784-32-10\n",
      "[INFO] epoch=1, loss=766.5438351\n",
      "[INFO] epoch=100, loss=52.5113633\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "nn = NeuralNetwork([X_train.shape[1], 32, 10])\n",
    "print(\"[INFO] {}\".format(nn))\n",
    "nn.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[INFO] evaluating network...']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       267\n",
      "           1       0.98      0.97      0.98       277\n",
      "           2       0.93      0.94      0.94       235\n",
      "           3       0.94      0.93      0.93       250\n",
      "           4       0.94      0.93      0.94       245\n",
      "           5       0.93      0.94      0.93       254\n",
      "           6       0.93      0.95      0.94       240\n",
      "           7       0.94      0.91      0.92       250\n",
      "           8       0.91      0.91      0.91       250\n",
      "           9       0.91      0.91      0.91       232\n",
      "\n",
      "    accuracy                           0.94      2500\n",
      "   macro avg       0.94      0.94      0.94      2500\n",
      "weighted avg       0.94      0.94      0.94      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate network\n",
    "print([\"[INFO] evaluating network...\"])\n",
    "predictions = nn.predict(X_test) # We take the model and predict the test class\n",
    "predictions = predictions.argmax(axis=1)\n",
    "print(classification_report(y_test.argmax(axis=1), predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv101",
   "language": "python",
   "name": "cv101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
